{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性的神经网络\n",
    "* 多输入模型\n",
    "* 多输出模型\n",
    "* 层组成的有向无环图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras灵活使用方式- 函数式API\n",
    "* 直接操作张量，把层当做函数来使用，接收张量并返回张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 11.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 12.4575\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 13.2928\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 14.5038\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 12us/step - loss: 16.4608\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 18.7319\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 21.3407\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 24.3240\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 27.3788\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 30.6928\n",
      "1000/1000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.61466973876953"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# 用Sequential模型实现线性神经网络\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "seq_model.summary()\n",
    "\n",
    "# 用函数API实现\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Model类将输入张量和输出张量转换为一个模型,  keras在后台检索从I到O所包含的每一层，\n",
    "                                        # 并将这些层组合成一个类图的数据结构\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()\n",
    "# 对Model实例进行编译、训练或评估时，与Sequential模型相同\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输入模型\n",
    "* 一个问答模型 - 一个自然语言描述问题输入到LSTM层， 一个文本片段输入到另一个LSTM层，\n",
    "* 然后两个层的输出连接起来输入到Dense层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulayer_size = 10000\n",
    "question_vocabulayer_size = 10000\n",
    "answer_vocabulayer_size = 500\n",
    "\n",
    "# 这里是文本输入，长度可变的整数序列， 对输入可以命名\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "# 将输入嵌入长度为64的向量\n",
    "embedded_text = layers.Embedding(text_vocabulayer_size, 64)(text_input)\n",
    "# 利用LSTM将向量编码为单个向量\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# 对问题进行相同的处理\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulayer_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 将编码后的问题和文本连接起来\n",
    "concatenated = layers.concatenate([encoded_text,encoded_question], axis=-1)\n",
    "\n",
    "# 添加一个softmax分类器\n",
    "answer = layers.Dense(answer_vocabulayer_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据输入到多输入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wukong/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 6.2145 - acc: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 465us/step - loss: 6.1962 - acc: 0.0360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 475us/step - loss: 6.1262 - acc: 0.0080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 485us/step - loss: 6.0438 - acc: 0.0120\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 5.9822 - acc: 0.0120\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 5.9128 - acc: 0.0070\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 461us/step - loss: 5.8371 - acc: 0.0100\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 5.7382 - acc: 0.0160\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 5.6384 - acc: 0.0200\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 452us/step - loss: 5.5638 - acc: 0.0240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f41c4c1beb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulayer_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulayer_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(answer_vocabulayer_size, size=(num_samples))\n",
    "answers = keras.utils.to_categorical(answers, answer_vocabulayer_size)\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "# 当对输入进行命名时，可以使用输入组成的字典来拟合\n",
    "# model.fit({'text':text, 'question':question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输出模型\n",
    "* 将输入数据（一个人的社交媒体发帖）输入到一维卷积神经网络，将结果分别发往3个不同的Dense层输出不同的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 输出层都应该具有名称\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss={'age':'mse',\n",
    "                                         'income':'categorical_crossentropy',\n",
    "                                         'gender':'binary_crossentropy'},\n",
    "                                   loss_weights={'age': 0.25,\n",
    "                                                 'income': 1.,\n",
    "                                                 'gender':10.})\n",
    "model.fit(posts, {'age':age_targets,\n",
    "                  'income':income_targets,\n",
    "                  'gender':gender_targets},\n",
    "         epochs = 10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层组成的有向无环图\n",
    "* Inception模块 - 模块的堆叠，每个模块像小型的独立网络，有助于网络分别学习空间特征和逐通道的特征\n",
    "* 残差连接 - 解决了大规模深度学习模型的梯度消失、表示瓶颈问题，和LSTM原理相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception\n",
    "from keras import layers\n",
    "\n",
    "# 每个分支都有相同的步幅值2\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "barach_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers,Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# 将分支输出连接到一起\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
    "\n",
    "\n",
    "# 残差连接\n",
    "# 1、恒等残差连接-如果特征图的尺寸相同\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "# 将原始x与输出特征相加\n",
    "y = layers.add([y, x])\n",
    "\n",
    "# 线性残差连接 - 特征图尺寸不同\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# 使用1X1卷积， 将原始x张量线性下采样与y具有相同的形状\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "# 将残差张亮与输出特征相加\n",
    " y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共享层权重\n",
    "* 几个分支同时对不同的输入集合学习 - 判断两个句子相似度，实例化一个共享LSTM层，该层的权重同时基于两个输入进行学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "\n",
    "# 将一个LSTM层实例化一次\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# 构建模型的左分支\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# 构建一个分类器\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 基于两个输入对模型进行训练\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将模型作为层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, applications\n",
    "from keras import Input\n",
    "\n",
    "# 图像处理基础模型是Xception网络\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "# 输入是250X250的RGB图像\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# 对相同的视觉模型调用两次\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "# 合并后的特征包含来自两个左右视觉输入中的信息\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
