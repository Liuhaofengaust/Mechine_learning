{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n",
      "tensor([[9.8432e+35, 3.0760e-41, 9.8712e+35],\n",
      "        [3.0760e-41, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.8988e+35, 3.0760e-41, 1.3816e+31]])\n",
      "tensor([[0.2647, 0.2367, 0.1072],\n",
      "        [0.8707, 0.6877, 0.0603],\n",
      "        [0.6321, 0.7626, 0.0459],\n",
      "        [0.7169, 0.8611, 0.4421],\n",
      "        [0.2048, 0.1991, 0.8619]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([5.5000, 3.0000])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[0.2318, 0.8591, 0.2948],\n",
      "        [0.4323, 0.9918, 0.3264],\n",
      "        [0.3204, 0.0389, 0.1559],\n",
      "        [0.2885, 0.8579, 0.1435],\n",
      "        [0.7869, 0.4712, 0.1504]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# 创建未初始化的张量\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "# 创建随机初始化的张量\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# long型的全0的Tensor\n",
    "y = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(y)\n",
    "\n",
    "# 自定义张量数据\n",
    "x = torch.tensor([5.5, 3.0])\n",
    "print(x)\n",
    "\n",
    "# 创建全1张量\n",
    "x = x.new_ones(5, 3, dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "# 通过tensor来创建\n",
    "x = torch.rand_like(x, dtype=torch.float)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2.2318, 2.8591, 2.2948],\n",
      "        [0.4323, 0.9918, 0.3264],\n",
      "        [0.3204, 0.0389, 0.1559],\n",
      "        [0.2885, 0.8579, 0.1435],\n",
      "        [0.7869, 0.4712, 0.1504]])\n",
      "tensor([2.2318, 2.8591, 2.2948, 0.4323, 0.9918, 0.3264, 0.3204, 0.0389, 0.1559,\n",
      "        0.2885, 0.8579, 0.1435, 0.7869, 0.4712, 0.1504])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (15) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8b927be7a666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 张量相加可以指定输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (15) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "result = torch.ones(5, 3)\n",
    "print(result)\n",
    "\n",
    "# 张量相加可以指定输出\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# 索引,索引出来的结果与元数据用一个内存，会修改源数据\n",
    "x = x[0, :]\n",
    "x += 1\n",
    "print(y)\n",
    "print(x[0, :])\n",
    "\n",
    "\n",
    "# 改变形状，数据不变，不共用内存\n",
    "y = x.view(15)\n",
    "z = x.view(-1, 5)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# 若不想共用内存，则拷贝下\n",
    "x_cp = x.clone().view(3)\n",
    "print(x_cp)\n",
    "\n",
    "# 将一个标量tensor转换成一个python number\n",
    "x = torch.randn(1)\n",
    "print(x.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运算的内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "\n",
    "# 新创建内存y，并指向y\n",
    "y = x + y\n",
    "\n",
    "# 利用索引避免新开内存\n",
    "y[:] = x + y\n",
    "\n",
    "# 利用out\n",
    "torch.add(x, y, out=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor和Numpy相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([2., 2., 2., 2., 2.]) tensor([1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wukong/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Tenson转numpy , 共享内存\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "# Numpy转Tensor， 共享内存\n",
    "import numpy as np\n",
    "c = np.ones(5)\n",
    "d = torch.from_numpy(c)\n",
    "print(c, d)\n",
    "\n",
    "# tensor方法是拷贝数据，不共享内存\n",
    "e = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
